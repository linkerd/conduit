---
dist: trusty
sudo: false

# We do not test pushes to branches, since they are redundant with the pull_request build
# for each branch. Take that, Big CI!
branches:
  only:
    - master

stages:
  - name: test
  - name: docker-deploy
    if: branch = master AND type != pull_request
  - name: integration-test
    if: branch = master AND type != pull_request

jobs:
  include:

    # Compile the application and run tests.
    - stage: test
      language: rust
      rust: stable
      cache: cargo
      script:
        - (cd proxy && cargo test --locked --no-default-features)

    - language: rust
      # Run proxy benchmarks in development mode. Requires nightly.
      # Failures are not fatal.
      rust: nightly-2018-05-26
      cache: cargo
      script:
        - (cd proxy && cargo test --benches --locked --no-default-features)

    - language: go
      # Quote the version number to avoid parsing issues like
      # https://github.com/travis-ci/gimme/issues/132.
      go: "1.10.2"
      go_import_path: github.com/runconduit/conduit
      cache:
        directories:
          - vendor
      install:
        - ./bin/dep ensure -vendor-only -v
        - ./bin/dep status -v
      script:
        # TODO decide whether protoc should be committed or not. If so, we shouldn't do
        # this or we should error if it dirties the repo.
        - ./bin/protoc-go.sh
        - go test -race -v ./...
        - go vet ./...

    - language: node_js
      node_js:
        - "10"
      cache: yarn
      before_install:
        - curl -o- -L https://yarnpkg.com/install.sh | bash -s -- --version 1.7.0
        - export PATH="$HOME/.yarn/bin:$PATH"
        - export NODE_ENV=test
      install:
        - ./bin/web
      script:
        - ./bin/web test --reporters dots

    - language: generic
      script:
        - |
          (
            . bin/_tag.sh
            for f in $( grep -lR --include=Dockerfile\* go-deps: . ) ; do
              validate_go_deps_tag $f
            done
          )

    # Push container images to Google Container Registry.
    - stage: docker-deploy

      language: generic
      services:
        - docker

      cache:
        directories:
          - "$HOME/google-cloud-sdk/"
          - "$HOME/.cache"

      before_install:
        - docker version

        - |
          # Install gcloud and kubectl.
          dir="${CLOUDSDK_INSTALL_DIR:-${HOME}}/google-cloud-sdk"
          (. bin/_gcp.sh ; install_gcloud_kubectl "$dir")
          . "$dir/path.bash.inc"
        - |
          # Configure gcloud with a service account.
          openssl aes-256-cbc -K $encrypted_6af64675f81c_key -iv $encrypted_6af64675f81c_iv -in .gcp.json.enc -out .gcp.json -d
          (. bin/_gcp.sh ; set_gcloud_config "$GCP_PROJECT" "$GCP_ZONE" "$GKE_CLUSTER")
        - |
          # Get a kubernetes context.
          (. bin/_gcp.sh ; get_k8s_ctx "$GCP_PROJECT" "$GCP_ZONE" "$GKE_CLUSTER")
        - gcloud version
        - kubectl version --short

      before_script:
        - gcloud docker --authorize-only
        - bin/docker-pull-deps
         # Pulling master helps with docker build cache, but may fail if we're
         # adding a new image to the mix.
        - bin/docker-pull master || echo "docker pull failed" >&2
        - |
          export CONDUIT_TAG=$(. bin/_tag.sh ; clean_head_root_tag)
          echo "CONDUIT_TAG=${CONDUIT_TAG}"
        - export BUILD_DEBUG=1 DOCKER_TRACE=1
        - export BUILD_CACHE_SHA_FILE="$HOME/.cache/build-cache-sha"
        - |
          if [ -f "$BUILD_CACHE_SHA_FILE" ]; then
            # If there's a build cache file, use it when building a new build cache image.
            export PROXY_BUILD_CACHE_IMAGE="gcr.io/runconduit/proxy-build:$(cat $BUILD_CACHE_SHA_FILE)"
            docker pull $PROXY_BUILD_CACHE_IMAGE
            docker image ls $PROXY_BUILD_CACHE_IMAGE
          else
            echo "Cache SHA file does not exist ($BUILD_CACHE_SHA_FILE)" >&2
          fi

      script:
        - |
          # If there was a prior cache image, it will be used as the basis for new cache.
          export PROXY_BUILD_CACHE_IMAGE=$(bin/docker-build-proxy-build)
          # Save off the proxy build cache so it can be reused
          docker push "$PROXY_BUILD_CACHE_IMAGE"
          bin/root-tag >$BUILD_CACHE_SHA_FILE
          echo "Proxy build cache: ${PROXY_BUILD_CACHE_IMAGE}" >&2
        - bin/docker-build

      after_success:
        - bin/docker-push-deps
        - bin/docker-push $CONDUIT_TAG
        - bin/docker-retag-all $CONDUIT_TAG master && bin/docker-push master
        - target/cli/linux/conduit install --conduit-version=$CONDUIT_TAG |tee conduit.yml
        - kubectl -n conduit apply -f conduit.yml --prune --selector='conduit.io/control-plane-component'

    # Run integration tests after container images have been published.
    - stage: integration-test

      language: go
      go: "1.10.2"
      go_import_path: github.com/runconduit/conduit
      services:
        - docker

      cache:
        directories:
          - vendor
          - "$HOME/google-cloud-sdk/"
          - "$HOME/.cache"

      install:
        - ./bin/dep ensure -vendor-only -v
        - ./bin/dep status -v

        - |
          # Install gcloud and kubectl.
          dir="${CLOUDSDK_INSTALL_DIR:-${HOME}}/google-cloud-sdk"
          (. bin/_gcp.sh ; install_gcloud_kubectl "$dir")
          . "$dir/path.bash.inc"
        - |
          # Configure gcloud with a service account.
          openssl aes-256-cbc -K $encrypted_6af64675f81c_key -iv $encrypted_6af64675f81c_iv -in .gcp.json.enc -out .gcp.json -d
          (. bin/_gcp.sh ; set_gcloud_config "$GCP_PROJECT" "$GCP_ZONE" "$GKE_CLUSTER")
        - |
          # Get a kubernetes context.
          (. bin/_gcp.sh ; get_k8s_ctx "$GCP_PROJECT" "$GCP_ZONE" "$GKE_CLUSTER")
        - |
          # Install conduit cli.
          version="git-$(git rev-parse --short=8 HEAD)"
          image="gcr.io/runconduit/cli-bin:$version"
          id=$(docker create $image)
          docker cp "$id:/out/conduit-linux" "./conduit"
        - gcloud version
        - kubectl version --short
        - ./conduit version --client

      script:
        - |
          # Run integration tests.
          version="$(./conduit version --client --short | tr -cd '[:alnum:]-')"
          ./bin/test-run `pwd`/conduit conduit-$version

      after_script:
        - |
          # Cleanup after integration test run.
          version="$(./conduit version --client --short | tr -cd '[:alnum:]-')"
          ./bin/test-cleanup conduit-$version

  # If we want to start building everything against bleeding-edge Rust nightly, we'll have
  # to enable:
  #
  # allow_failures:
  #   - rust: nightly
  # fast_finish: true

notifications:
  email:
    on_success: never
